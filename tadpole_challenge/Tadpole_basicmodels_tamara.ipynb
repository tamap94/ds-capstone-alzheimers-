{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further modeling - Tadpole challenge \n",
    "\n",
    "In this Notebook different models will be used on the numerical dataset \n",
    "We will use the already modified dataset which only contains the data from the first visit. Further, we will test it also separately on other data and the brain data only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, precision_recall_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Import TensorFlow packages \n",
    "\n",
    "import tensorflow as tf   \n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, InputLayer, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://neuefische-mlflow/mlflow-artifacts/56', experiment_id='56', lifecycle_stage='active', name='alzbusters_numeric_models', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages to see models in MLFlow \n",
    "import logging\n",
    "import parsenvy\n",
    "\n",
    "from logging import getLogger\n",
    "import mlflow\n",
    "from config_tp import TRACKING_URI, EXPERIMENT_NAME\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed dataset \n",
    "df=pd.read_csv('../tadpole_challenge/df_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all the empty rows and columns with the weird entries \n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "#drop the column with the IDs and strange symbols\n",
    "df.drop(columns=df[['PTID','ABETA','PTAU']], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>101.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>170.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>347.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>324.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>108.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>279.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>314.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>305.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>300.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>81.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TAU\n",
       "18    101.20\n",
       "19    170.40\n",
       "30    347.80\n",
       "36    324.80\n",
       "90    108.20\n",
       "...      ...\n",
       "1792  279.90\n",
       "1793  314.60\n",
       "1794  305.00\n",
       "1796  300.10\n",
       "1805   81.54\n",
       "\n",
       "[625 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert everything to numerical values \n",
    "df[['TAU']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_dummies for the PTGENDER and APOE4 column \n",
    "df=pd.get_dummies(df, columns=['PTGENDER', 'APOE4'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "AGE                0\n",
       "FDG                0\n",
       "AV45               0\n",
       "TAU                0\n",
       "CDRSB              0\n",
       "ADAS11             0\n",
       "ADAS13             0\n",
       "MMSE               0\n",
       "RAVLT_immediate    0\n",
       "Ventricles         0\n",
       "Hippocampus        0\n",
       "WholeBrain         0\n",
       "Entorhinal         0\n",
       "MidTemp            0\n",
       "DX                 0\n",
       "PTGENDER_Female    0\n",
       "PTGENDER_Male      0\n",
       "APOE4_0.0          0\n",
       "APOE4_1.0          0\n",
       "APOE4_2.0          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TAU\"].replace(\"<80\",np.nan, inplace=True)\n",
    "df[\"TAU\"].replace(\">1300\",np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the entries in DX into 0-2 values \n",
    "def replace_dx(df, feature):\n",
    "    df[feature] = df[feature].replace('CN', 0)\n",
    "    df[feature] = df[feature].replace('MCI', 1)\n",
    "    df[feature] = df[feature].replace('Dementia', 2)\n",
    "    return df\n",
    "\n",
    "col_pass = ['DX']\n",
    "\n",
    "for col in col_pass: \n",
    "    df = replace_dx(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split \n",
    "\n",
    "X=df.drop('DX', axis=1)\n",
    "y=df['DX']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify = y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Standard Scaler for the numeric data \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.start_run(run_name='1_SVM_scaled')\n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with a SVM model \n",
    "model = SVC(kernel='rbf')\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821656050955414\n",
      "0.9465811965811965\n"
     ]
    }
   ],
   "source": [
    "# Check out the metrics\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print(acc_test)\n",
    "acc_train=accuracy_score(y_train, model.predict(X_train_scaled))\n",
    "print(acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={'test-accuracy': 0.821656050955414, 'train-accuracy': 0.9465811965811965}, params={}, tags={'mlflow.runName': '1_SVM_scaled',\n",
       " 'mlflow.source.git.commit': 'd605302d01200a4536da993e7ae45ed46232dc60',\n",
       " 'mlflow.source.name': '/Users/tamarapallien/neuefische/capstone '\n",
       "                       '/ds-capstone-alzheimers-/.venv/lib/python3.9/site-packages/ipykernel_launcher.py',\n",
       " 'mlflow.source.type': 'LOCAL',\n",
       " 'mlflow.user': 'tamarapallien'}>, info=<RunInfo: artifact_uri='s3://neuefische-mlflow/mlflow-artifacts/56/ae0416924545459194a17cba06626e13/artifacts', end_time=1661779923261, experiment_id='56', lifecycle_stage='active', run_id='ae0416924545459194a17cba06626e13', run_uuid='ae0416924545459194a17cba06626e13', start_time=1661779923035, status='FINISHED', user_id='tamarapallien'>>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"accuracy\", acc_train)\n",
    "mlflow.log_metric(\"test-\" + \"accuracy\", acc_test)\n",
    "\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()\n",
    "\n",
    "mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.start_run(run_name='2_KNN_scaled')\n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a KNN model \n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(X_train_scaled, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6751592356687898\n",
      "0.9465811965811965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamarapallien/neuefische/capstone /ds-capstone-alzheimers-/.venv/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "y_pred=knn.predict(X_test_scaled)\n",
    "\n",
    "# Check out the metrics\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print(acc_test)\n",
    "acc_train=accuracy_score(y_train, model.predict(X_train_scaled))\n",
    "print(acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={'test-accuracy': 0.6751592356687898, 'train-accuracy': 0.9465811965811965}, params={}, tags={'mlflow.runName': '2_KNN_scaled',\n",
       " 'mlflow.source.git.commit': 'd605302d01200a4536da993e7ae45ed46232dc60',\n",
       " 'mlflow.source.name': '/Users/tamarapallien/neuefische/capstone '\n",
       "                       '/ds-capstone-alzheimers-/.venv/lib/python3.9/site-packages/ipykernel_launcher.py',\n",
       " 'mlflow.source.type': 'LOCAL',\n",
       " 'mlflow.user': 'tamarapallien'}>, info=<RunInfo: artifact_uri='s3://neuefische-mlflow/mlflow-artifacts/56/2079dd923097433e9727c4a80ccd00f1/artifacts', end_time=1661779923823, experiment_id='56', lifecycle_stage='active', run_id='2079dd923097433e9727c4a80ccd00f1', run_uuid='2079dd923097433e9727c4a80ccd00f1', start_time=1661779923432, status='FINISHED', user_id='tamarapallien'>>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"accuracy\", acc_train)\n",
    "mlflow.log_metric(\"test-\" + \"accuracy\", acc_test)\n",
    "\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()\n",
    "\n",
    "mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try out as simple DNN model \n",
    "mlflow.start_run(run_name='3_DNN_scaled')\n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.asarray(X_train_scaled).astype(np.float32)\n",
    "y_train=np.asarray(y_train).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 15:32:04.090009: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-29 15:32:04.090283: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Built a model \n",
    "model=Sequential()\n",
    "model.add(Dense(units=20, activation='relu'))\n",
    "model.add(Dense(units=20, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model \n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 15:32:04.330249: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-08-29 15:32:04.583001: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 31ms/step - loss: 0.7197 - accuracy: 0.4251 - val_loss: 0.5331 - val_accuracy: 0.4894\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5881 - accuracy: 0.4572 - val_loss: 0.3870 - val_accuracy: 0.4894\n",
      "Epoch 3/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.4864 - accuracy: 0.6667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 15:32:04.942848: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4503 - accuracy: 0.5535 - val_loss: 0.2661 - val_accuracy: 0.5426\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3670 - accuracy: 0.5535 - val_loss: 0.1516 - val_accuracy: 0.5638\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2791 - accuracy: 0.5722 - val_loss: 0.0352 - val_accuracy: 0.5851\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1633 - accuracy: 0.6096 - val_loss: -0.0972 - val_accuracy: 0.6170\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0605 - accuracy: 0.6096 - val_loss: -0.2437 - val_accuracy: 0.6277\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -0.0910 - accuracy: 0.6203 - val_loss: -0.4041 - val_accuracy: 0.6489\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -0.1969 - accuracy: 0.6123 - val_loss: -0.6043 - val_accuracy: 0.6596\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -0.3643 - accuracy: 0.6444 - val_loss: -0.8405 - val_accuracy: 0.6596\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -0.5516 - accuracy: 0.6551 - val_loss: -1.1110 - val_accuracy: 0.6596\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -0.8625 - accuracy: 0.6658 - val_loss: -1.4507 - val_accuracy: 0.6596\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -1.0417 - accuracy: 0.6524 - val_loss: -1.8551 - val_accuracy: 0.6596\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -1.3152 - accuracy: 0.6711 - val_loss: -2.3020 - val_accuracy: 0.6702\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -1.7906 - accuracy: 0.6765 - val_loss: -2.8242 - val_accuracy: 0.6702\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -2.1443 - accuracy: 0.6684 - val_loss: -3.4280 - val_accuracy: 0.6702\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -2.6827 - accuracy: 0.6551 - val_loss: -4.1490 - val_accuracy: 0.6702\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -3.3483 - accuracy: 0.6925 - val_loss: -5.0068 - val_accuracy: 0.6809\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -3.9211 - accuracy: 0.6765 - val_loss: -6.0071 - val_accuracy: 0.6809\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -4.7239 - accuracy: 0.6631 - val_loss: -7.0994 - val_accuracy: 0.6915\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 15ms/step - loss: -5.5189 - accuracy: 0.6738 - val_loss: -8.3493 - val_accuracy: 0.6809\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -6.5579 - accuracy: 0.6925 - val_loss: -9.7353 - val_accuracy: 0.6809\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -7.6048 - accuracy: 0.6845 - val_loss: -11.3498 - val_accuracy: 0.6809\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -8.8313 - accuracy: 0.6658 - val_loss: -13.0706 - val_accuracy: 0.6809\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -10.6499 - accuracy: 0.6952 - val_loss: -14.9056 - val_accuracy: 0.6915\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -11.6096 - accuracy: 0.6872 - val_loss: -17.1377 - val_accuracy: 0.6915\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -13.7818 - accuracy: 0.6791 - val_loss: -19.5402 - val_accuracy: 0.6915\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -15.3338 - accuracy: 0.7005 - val_loss: -22.1486 - val_accuracy: 0.6809\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -17.7910 - accuracy: 0.6898 - val_loss: -25.0782 - val_accuracy: 0.6809\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -20.0285 - accuracy: 0.6979 - val_loss: -28.3456 - val_accuracy: 0.6809\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: -22.3840 - accuracy: 0.6898 - val_loss: -31.8190 - val_accuracy: 0.6809\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -26.4984 - accuracy: 0.6898 - val_loss: -35.6396 - val_accuracy: 0.6702\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: -29.0780 - accuracy: 0.7032 - val_loss: -39.6478 - val_accuracy: 0.6596\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: -31.4610 - accuracy: 0.6979 - val_loss: -44.1826 - val_accuracy: 0.6702\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: -34.0919 - accuracy: 0.7059 - val_loss: -48.9157 - val_accuracy: 0.6702\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: -37.9390 - accuracy: 0.7193 - val_loss: -53.7401 - val_accuracy: 0.6809\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -41.0147 - accuracy: 0.7139 - val_loss: -58.8688 - val_accuracy: 0.6702\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: -44.6091 - accuracy: 0.7166 - val_loss: -64.5136 - val_accuracy: 0.6596\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -50.2809 - accuracy: 0.7166 - val_loss: -70.2429 - val_accuracy: 0.6489\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -56.1251 - accuracy: 0.7219 - val_loss: -76.7084 - val_accuracy: 0.6489\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -61.5810 - accuracy: 0.7219 - val_loss: -83.5838 - val_accuracy: 0.6489\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -64.4673 - accuracy: 0.7219 - val_loss: -90.2389 - val_accuracy: 0.6277\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -71.6491 - accuracy: 0.7166 - val_loss: -97.4462 - val_accuracy: 0.6277\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -74.3946 - accuracy: 0.7193 - val_loss: -105.0565 - val_accuracy: 0.6277\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -81.2112 - accuracy: 0.7273 - val_loss: -112.9791 - val_accuracy: 0.6277\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -91.6978 - accuracy: 0.7166 - val_loss: -121.4865 - val_accuracy: 0.6277\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -92.6515 - accuracy: 0.7273 - val_loss: -130.3138 - val_accuracy: 0.6277\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -101.7157 - accuracy: 0.7246 - val_loss: -139.2279 - val_accuracy: 0.6277\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -110.1723 - accuracy: 0.7273 - val_loss: -148.9946 - val_accuracy: 0.6277\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -116.0153 - accuracy: 0.7246 - val_loss: -159.2677 - val_accuracy: 0.6383\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -123.1210 - accuracy: 0.7166 - val_loss: -169.6227 - val_accuracy: 0.6383\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: -136.7725 - accuracy: 0.7246 - val_loss: -181.0438 - val_accuracy: 0.6383\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -142.0275 - accuracy: 0.7193 - val_loss: -192.9622 - val_accuracy: 0.6383\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -148.8254 - accuracy: 0.7219 - val_loss: -204.9659 - val_accuracy: 0.6277\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -162.2065 - accuracy: 0.7219 - val_loss: -217.5256 - val_accuracy: 0.6277\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -168.4540 - accuracy: 0.7193 - val_loss: -230.7921 - val_accuracy: 0.6383\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -180.5989 - accuracy: 0.7219 - val_loss: -244.4987 - val_accuracy: 0.6383\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -193.0536 - accuracy: 0.7193 - val_loss: -259.0451 - val_accuracy: 0.6383\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -208.2090 - accuracy: 0.7193 - val_loss: -273.9455 - val_accuracy: 0.6383\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -221.3932 - accuracy: 0.7246 - val_loss: -289.7813 - val_accuracy: 0.6383\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -223.3009 - accuracy: 0.7193 - val_loss: -305.6430 - val_accuracy: 0.6383\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -233.6703 - accuracy: 0.7112 - val_loss: -321.8481 - val_accuracy: 0.6383\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -245.3993 - accuracy: 0.7166 - val_loss: -338.7899 - val_accuracy: 0.6383\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -258.9741 - accuracy: 0.7139 - val_loss: -355.5321 - val_accuracy: 0.6383\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -270.4221 - accuracy: 0.7086 - val_loss: -373.6785 - val_accuracy: 0.6383\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -293.8877 - accuracy: 0.7139 - val_loss: -392.4042 - val_accuracy: 0.6383\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -299.6414 - accuracy: 0.7112 - val_loss: -412.1575 - val_accuracy: 0.6383\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -324.4573 - accuracy: 0.7139 - val_loss: -430.2013 - val_accuracy: 0.6383\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -349.5056 - accuracy: 0.7059 - val_loss: -451.4611 - val_accuracy: 0.6383\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -356.2211 - accuracy: 0.7059 - val_loss: -471.1015 - val_accuracy: 0.6383\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -362.6700 - accuracy: 0.7059 - val_loss: -493.0623 - val_accuracy: 0.6383\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -379.3534 - accuracy: 0.6952 - val_loss: -514.6872 - val_accuracy: 0.6383\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: -389.6776 - accuracy: 0.7086 - val_loss: -537.1678 - val_accuracy: 0.6383\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -425.7998 - accuracy: 0.7032 - val_loss: -560.0537 - val_accuracy: 0.6383\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -424.0350 - accuracy: 0.7032 - val_loss: -583.7146 - val_accuracy: 0.6383\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -431.7134 - accuracy: 0.6952 - val_loss: -606.1678 - val_accuracy: 0.6383\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -467.9590 - accuracy: 0.7032 - val_loss: -630.0953 - val_accuracy: 0.6277\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -480.3357 - accuracy: 0.7059 - val_loss: -655.1661 - val_accuracy: 0.6277\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -491.3019 - accuracy: 0.7005 - val_loss: -681.1696 - val_accuracy: 0.6277\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -521.9594 - accuracy: 0.7032 - val_loss: -706.7329 - val_accuracy: 0.6383\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -538.6584 - accuracy: 0.7005 - val_loss: -733.6176 - val_accuracy: 0.6383\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: -569.8528 - accuracy: 0.6952 - val_loss: -760.9376 - val_accuracy: 0.6383\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -611.4670 - accuracy: 0.7059 - val_loss: -787.9401 - val_accuracy: 0.6383\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -612.3181 - accuracy: 0.6979 - val_loss: -817.3568 - val_accuracy: 0.6383\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -615.6233 - accuracy: 0.6979 - val_loss: -846.6984 - val_accuracy: 0.6383\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -651.2878 - accuracy: 0.7005 - val_loss: -875.6445 - val_accuracy: 0.6383\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -683.4491 - accuracy: 0.6979 - val_loss: -908.5945 - val_accuracy: 0.6383\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -713.3510 - accuracy: 0.6925 - val_loss: -940.3229 - val_accuracy: 0.6383\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: -720.6733 - accuracy: 0.6925 - val_loss: -972.9047 - val_accuracy: 0.6383\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -762.5230 - accuracy: 0.6925 - val_loss: -1007.3177 - val_accuracy: 0.6383\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -783.5726 - accuracy: 0.7032 - val_loss: -1040.8506 - val_accuracy: 0.6383\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -802.2715 - accuracy: 0.7032 - val_loss: -1075.2953 - val_accuracy: 0.6383\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -825.7805 - accuracy: 0.7005 - val_loss: -1109.3351 - val_accuracy: 0.6383\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -807.3010 - accuracy: 0.6952 - val_loss: -1144.5963 - val_accuracy: 0.6383\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -888.5876 - accuracy: 0.7112 - val_loss: -1178.6350 - val_accuracy: 0.6383\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -926.7830 - accuracy: 0.6979 - val_loss: -1216.1300 - val_accuracy: 0.6383\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -941.0433 - accuracy: 0.6925 - val_loss: -1255.0674 - val_accuracy: 0.6383\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -1006.4406 - accuracy: 0.6952 - val_loss: -1295.3798 - val_accuracy: 0.6383\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -1006.2847 - accuracy: 0.6845 - val_loss: -1335.6997 - val_accuracy: 0.6383\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -998.6693 - accuracy: 0.6925 - val_loss: -1376.4749 - val_accuracy: 0.6277\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -1091.6603 - accuracy: 0.6952 - val_loss: -1416.0868 - val_accuracy: 0.6277\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -1068.1702 - accuracy: 0.6898 - val_loss: -1456.5632 - val_accuracy: 0.6277\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 14ms/step - loss: -1129.8490 - accuracy: 0.6818 - val_loss: -1500.0839 - val_accuracy: 0.6277\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 13ms/step - loss: -1150.8447 - accuracy: 0.7032 - val_loss: -1543.7614 - val_accuracy: 0.6383\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: -1178.5292 - accuracy: 0.6845 - val_loss: -1588.5706 - val_accuracy: 0.6489\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -1193.9355 - accuracy: 0.6952 - val_loss: -1631.6703 - val_accuracy: 0.6383\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -1297.4075 - accuracy: 0.6898 - val_loss: -1678.2112 - val_accuracy: 0.6383\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -1296.5782 - accuracy: 0.6845 - val_loss: -1725.5972 - val_accuracy: 0.6383\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -1383.4629 - accuracy: 0.6979 - val_loss: -1774.0762 - val_accuracy: 0.6277\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -1353.1204 - accuracy: 0.6898 - val_loss: -1821.3467 - val_accuracy: 0.6277\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -1430.8188 - accuracy: 0.6872 - val_loss: -1871.4716 - val_accuracy: 0.6277\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -1473.4036 - accuracy: 0.6952 - val_loss: -1920.8333 - val_accuracy: 0.6277\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -1494.2269 - accuracy: 0.6898 - val_loss: -1971.5127 - val_accuracy: 0.6277\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -1480.5503 - accuracy: 0.6898 - val_loss: -2023.9612 - val_accuracy: 0.6277\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -1621.9907 - accuracy: 0.6872 - val_loss: -2076.8569 - val_accuracy: 0.6277\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -1561.6571 - accuracy: 0.6872 - val_loss: -2127.8013 - val_accuracy: 0.6277\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -1630.8773 - accuracy: 0.6898 - val_loss: -2180.3049 - val_accuracy: 0.6277\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -1643.3645 - accuracy: 0.6845 - val_loss: -2235.8372 - val_accuracy: 0.6277\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -1742.8556 - accuracy: 0.6925 - val_loss: -2290.2183 - val_accuracy: 0.6277\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -1770.7064 - accuracy: 0.6872 - val_loss: -2348.3591 - val_accuracy: 0.6277\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -1832.3263 - accuracy: 0.6845 - val_loss: -2406.6069 - val_accuracy: 0.6170\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -1884.3345 - accuracy: 0.6791 - val_loss: -2464.5044 - val_accuracy: 0.6170\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -1943.4176 - accuracy: 0.6925 - val_loss: -2526.2710 - val_accuracy: 0.6170\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -1892.8373 - accuracy: 0.6818 - val_loss: -2588.1042 - val_accuracy: 0.6170\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -2055.7693 - accuracy: 0.6765 - val_loss: -2647.1567 - val_accuracy: 0.6170\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -2049.8425 - accuracy: 0.6872 - val_loss: -2708.6655 - val_accuracy: 0.6170\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -2131.7849 - accuracy: 0.6845 - val_loss: -2773.4363 - val_accuracy: 0.6170\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -2120.9993 - accuracy: 0.6818 - val_loss: -2837.4226 - val_accuracy: 0.6170\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -2140.8140 - accuracy: 0.6872 - val_loss: -2901.3904 - val_accuracy: 0.6170\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -2289.1873 - accuracy: 0.6818 - val_loss: -2965.5337 - val_accuracy: 0.6170\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -2217.6965 - accuracy: 0.6872 - val_loss: -3027.1216 - val_accuracy: 0.6170\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -2432.7798 - accuracy: 0.6845 - val_loss: -3096.4441 - val_accuracy: 0.6170\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -2415.8022 - accuracy: 0.6791 - val_loss: -3167.3398 - val_accuracy: 0.6170\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -2397.5295 - accuracy: 0.6791 - val_loss: -3236.2542 - val_accuracy: 0.6170\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -2534.6160 - accuracy: 0.6872 - val_loss: -3307.2661 - val_accuracy: 0.6064\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -2554.0044 - accuracy: 0.6738 - val_loss: -3376.7966 - val_accuracy: 0.6064\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -2609.4258 - accuracy: 0.6738 - val_loss: -3449.7327 - val_accuracy: 0.6064\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -2677.4692 - accuracy: 0.6818 - val_loss: -3524.8918 - val_accuracy: 0.6064\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: -2816.6423 - accuracy: 0.6738 - val_loss: -3597.0361 - val_accuracy: 0.6064\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -2823.7556 - accuracy: 0.6791 - val_loss: -3673.5195 - val_accuracy: 0.5957\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -2855.3176 - accuracy: 0.6711 - val_loss: -3749.2754 - val_accuracy: 0.5957\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -2898.3921 - accuracy: 0.6818 - val_loss: -3825.2234 - val_accuracy: 0.6064\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -3035.0630 - accuracy: 0.6711 - val_loss: -3904.9497 - val_accuracy: 0.6064\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -2892.9126 - accuracy: 0.6845 - val_loss: -3981.6997 - val_accuracy: 0.5957\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: -3111.2998 - accuracy: 0.6872 - val_loss: -4058.9177 - val_accuracy: 0.6064\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 12ms/step - loss: -3080.0750 - accuracy: 0.6898 - val_loss: -4139.0854 - val_accuracy: 0.6064\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -3279.5132 - accuracy: 0.6738 - val_loss: -4216.7144 - val_accuracy: 0.6064\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -3188.7073 - accuracy: 0.6845 - val_loss: -4303.1997 - val_accuracy: 0.6064\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -3242.7732 - accuracy: 0.6765 - val_loss: -4379.2090 - val_accuracy: 0.5957\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -3418.5635 - accuracy: 0.6845 - val_loss: -4465.3911 - val_accuracy: 0.5957\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -3315.4980 - accuracy: 0.6765 - val_loss: -4549.6738 - val_accuracy: 0.5957\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -3509.3667 - accuracy: 0.6818 - val_loss: -4633.8281 - val_accuracy: 0.5957\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -3549.9861 - accuracy: 0.6818 - val_loss: -4720.1152 - val_accuracy: 0.5957\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -3728.6819 - accuracy: 0.6711 - val_loss: -4806.4634 - val_accuracy: 0.5957\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -3737.9963 - accuracy: 0.6738 - val_loss: -4890.9609 - val_accuracy: 0.5957\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -3805.7590 - accuracy: 0.6791 - val_loss: -4984.9243 - val_accuracy: 0.5957\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -3755.7642 - accuracy: 0.6684 - val_loss: -5072.3330 - val_accuracy: 0.6064\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -3854.0315 - accuracy: 0.6765 - val_loss: -5160.8457 - val_accuracy: 0.6064\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -3947.2073 - accuracy: 0.6791 - val_loss: -5252.8213 - val_accuracy: 0.6064\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -3920.2891 - accuracy: 0.6765 - val_loss: -5342.1255 - val_accuracy: 0.6064\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -4095.9565 - accuracy: 0.6738 - val_loss: -5436.3115 - val_accuracy: 0.6064\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -4207.9053 - accuracy: 0.6765 - val_loss: -5533.9351 - val_accuracy: 0.6064\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -4242.4004 - accuracy: 0.6818 - val_loss: -5627.9619 - val_accuracy: 0.6064\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -4083.1646 - accuracy: 0.6791 - val_loss: -5721.3057 - val_accuracy: 0.6064\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -4260.0820 - accuracy: 0.6845 - val_loss: -5814.1963 - val_accuracy: 0.6064\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -4503.1689 - accuracy: 0.6711 - val_loss: -5908.4360 - val_accuracy: 0.6064\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -4415.5229 - accuracy: 0.6765 - val_loss: -6007.8882 - val_accuracy: 0.6064\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -4527.9067 - accuracy: 0.6738 - val_loss: -6103.7881 - val_accuracy: 0.6064\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -4632.0137 - accuracy: 0.6738 - val_loss: -6204.9067 - val_accuracy: 0.6064\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -4676.3408 - accuracy: 0.6738 - val_loss: -6304.9180 - val_accuracy: 0.6064\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -4784.5479 - accuracy: 0.6631 - val_loss: -6404.8652 - val_accuracy: 0.6064\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -4688.6792 - accuracy: 0.6791 - val_loss: -6506.0981 - val_accuracy: 0.6064\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -5138.0205 - accuracy: 0.6872 - val_loss: -6607.1108 - val_accuracy: 0.6064\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -4849.6284 - accuracy: 0.6711 - val_loss: -6717.9277 - val_accuracy: 0.6064\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -5063.0850 - accuracy: 0.6711 - val_loss: -6822.4204 - val_accuracy: 0.6064\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -5328.0361 - accuracy: 0.6738 - val_loss: -6930.5078 - val_accuracy: 0.6064\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -5375.7646 - accuracy: 0.6818 - val_loss: -7044.2622 - val_accuracy: 0.6064\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -5565.8667 - accuracy: 0.6738 - val_loss: -7156.1538 - val_accuracy: 0.6064\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -5496.2104 - accuracy: 0.6765 - val_loss: -7272.9180 - val_accuracy: 0.6064\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -5333.0615 - accuracy: 0.6738 - val_loss: -7381.9673 - val_accuracy: 0.6064\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -5628.3125 - accuracy: 0.6658 - val_loss: -7496.3057 - val_accuracy: 0.6064\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -5662.0591 - accuracy: 0.6818 - val_loss: -7610.8369 - val_accuracy: 0.6064\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -5911.9404 - accuracy: 0.6711 - val_loss: -7725.5601 - val_accuracy: 0.6064\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -5927.3477 - accuracy: 0.6711 - val_loss: -7836.4766 - val_accuracy: 0.6064\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -5856.0737 - accuracy: 0.6684 - val_loss: -7954.4497 - val_accuracy: 0.6064\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -6278.1919 - accuracy: 0.6791 - val_loss: -8073.9624 - val_accuracy: 0.6064\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -6322.6841 - accuracy: 0.6818 - val_loss: -8198.6494 - val_accuracy: 0.6064\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -6483.7383 - accuracy: 0.6765 - val_loss: -8323.2090 - val_accuracy: 0.6064\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -6389.8110 - accuracy: 0.6684 - val_loss: -8447.2783 - val_accuracy: 0.6064\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 0s 10ms/step - loss: -6375.3550 - accuracy: 0.6684 - val_loss: -8572.8955 - val_accuracy: 0.6064\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 11ms/step - loss: -6731.7744 - accuracy: 0.6711 - val_loss: -8695.4404 - val_accuracy: 0.6064\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -6714.2661 - accuracy: 0.6711 - val_loss: -8819.8398 - val_accuracy: 0.6064\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -6734.6699 - accuracy: 0.6711 - val_loss: -8950.1318 - val_accuracy: 0.6064\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -6903.8535 - accuracy: 0.6658 - val_loss: -9078.2441 - val_accuracy: 0.6064\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -6950.7100 - accuracy: 0.6684 - val_loss: -9204.7637 - val_accuracy: 0.6064\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: -7176.6123 - accuracy: 0.6631 - val_loss: -9338.8135 - val_accuracy: 0.6064\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -7025.8711 - accuracy: 0.6711 - val_loss: -9465.4043 - val_accuracy: 0.6064\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -7381.7856 - accuracy: 0.6791 - val_loss: -9590.4033 - val_accuracy: 0.6064\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -7106.1265 - accuracy: 0.6604 - val_loss: -9720.2939 - val_accuracy: 0.6064\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 8ms/step - loss: -7664.7563 - accuracy: 0.6711 - val_loss: -9851.9502 - val_accuracy: 0.6064\n"
     ]
    }
   ],
   "source": [
    "#Train the model \n",
    "training = model.fit(X_train_scaled, y_train, batch_size=48, validation_split=0.2, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(training.history['accuracy'])\n",
    "plt.plot(training.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 15:32:20.009970: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predd = model.predict(X_test_scaled)\n",
    "y_pred = (y_predd>0.5).astype(int)\n",
    "\n",
    "# Plotting the confusing matrix\n",
    "mat = confusion_matrix(y_test, y_pred.round())\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6114649681528662\n"
     ]
    }
   ],
   "source": [
    "# Check out the metrics\n",
    "acc_train = accuracy_score(y_train, model.predict(X_train_scaled).astype(int))\n",
    "acc_test = accuracy_score(y_test, y_pred.round())\n",
    "print(acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={'test-accuracy': 0.6114649681528662, 'train-accuracy': 0.6388888888888888}, params={}, tags={'mlflow.runName': '3_DNN_scaled',\n",
       " 'mlflow.source.git.commit': 'd605302d01200a4536da993e7ae45ed46232dc60',\n",
       " 'mlflow.source.name': '/Users/tamarapallien/neuefische/capstone '\n",
       "                       '/ds-capstone-alzheimers-/.venv/lib/python3.9/site-packages/ipykernel_launcher.py',\n",
       " 'mlflow.source.type': 'LOCAL',\n",
       " 'mlflow.user': 'tamarapallien'}>, info=<RunInfo: artifact_uri='s3://neuefische-mlflow/mlflow-artifacts/56/76948f82defa46fb8ecc4b61d38104d4/artifacts', end_time=1661779940290, experiment_id='56', lifecycle_stage='active', run_id='76948f82defa46fb8ecc4b61d38104d4', run_uuid='76948f82defa46fb8ecc4b61d38104d4', start_time=1661779923981, status='FINISHED', user_id='tamarapallien'>>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"accuracy\", acc_train)\n",
    "mlflow.log_metric(\"test-\" + \"accuracy\", acc_test)\n",
    "\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()\n",
    "\n",
    "mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try out as simple DNN model \n",
    "mlflow.start_run(run_name='4_SVM_gs_scaled')\n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 420 candidates, totalling 2100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid=[{'C': [0.01, 0.1, 1, 10, 100], 'degree': [2, 3, 4],\n",
       "                          'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 'auto',\n",
       "                                    'scale'],\n",
       "                          'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}],\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the SVM performed the best we will perform a GridSearch to see if we can improve our outcome \n",
    "# Define hyperparameter grid \n",
    "param_grid = [{'kernel': ['rbf', 'linear', 'poly', 'sigmoid'], \n",
    "               'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 'auto', 'scale'],\n",
    "               'C': [0.01, 0.1, 1, 10, 100],\n",
    "               'degree': [2, 3, 4]\n",
    "              }]\n",
    "\n",
    "gs = GridSearchCV(SVC(), param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'degree': 2, 'gamma': 0.0001, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Print best parameters \n",
    "print('Best Parameters:', gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy 0.947\n"
     ]
    }
   ],
   "source": [
    "# Print best score\n",
    "print('Best accuracy', gs.best_score_.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "best_model = gs.best_estimator_\n",
    "y_pred_tuned = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8980891719745223\n"
     ]
    }
   ],
   "source": [
    "# Check out the metrics\n",
    "acc_train = accuracy_score(y_train, best_model.predict(X_train_scaled))\n",
    "acc_test = accuracy_score(y_test, y_pred_tuned)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={'test-accuracy': 0.8980891719745223, 'train-accuracy': 0.9615384615384616}, params={}, tags={'mlflow.runName': '4_SVM_gs_scaled',\n",
       " 'mlflow.source.git.commit': 'd605302d01200a4536da993e7ae45ed46232dc60',\n",
       " 'mlflow.source.name': '/Users/tamarapallien/neuefische/capstone '\n",
       "                       '/ds-capstone-alzheimers-/.venv/lib/python3.9/site-packages/ipykernel_launcher.py',\n",
       " 'mlflow.source.type': 'LOCAL',\n",
       " 'mlflow.user': 'tamarapallien'}>, info=<RunInfo: artifact_uri='s3://neuefische-mlflow/mlflow-artifacts/56/c1d651cb4d1249bfa3df7de01d9b3bd6/artifacts', end_time=1661779945257, experiment_id='56', lifecycle_stage='active', run_id='c1d651cb4d1249bfa3df7de01d9b3bd6', run_uuid='c1d651cb4d1249bfa3df7de01d9b3bd6', start_time=1661779940456, status='FINISHED', user_id='tamarapallien'>>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"accuracy\", acc_train)\n",
    "mlflow.log_metric(\"test-\" + \"accuracy\", acc_test)\n",
    "\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()\n",
    "\n",
    "mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the df_other dataframe \n",
    "df_other=pd.read_csv('../tadpole_challenge/df_other.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2122, 11)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_other.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_other= df_other.drop('DX', axis=1)\n",
    "y_other=df_other['DX']\n",
    "X_train_other, X_test_other, y_train_other, y_test_other=train_test_split(X_other, y_other, random_state=42, stratify=y_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_other['AGE'].fillna(X_train_other['AGE'].mean(), inplace=True);\n",
    "X_test_other['AGE'].fillna(X_train_other['AGE'].mean(), inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the KNN imputer to fill the other missing values in the X_train and apply this to X_test \n",
    "#define imputer\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "\n",
    "# fit on the dataset\n",
    "imputer.fit(X_train_other)\n",
    "\n",
    "# transform X_train und X_test\n",
    "X_train_other_trans = imputer.transform(X_train_other)\n",
    "X_test_other_trans = imputer.transform(X_test_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_other_trans_scaled=scaler.fit_transform(X_train_other_trans)\n",
    "X_test_other_trans_scaled=scaler.transform(X_test_other_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.start_run(run_name='5_SVM_other_scaled_trans')\n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with a SVM model \n",
    "model = SVC(kernel='rbf')\n",
    "model.fit(X_train_other_trans_scaled, y_train_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test_other_trans_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9152542372881356\n",
      "0.9296040226272785\n"
     ]
    }
   ],
   "source": [
    "# Check out the metrics\n",
    "acc_test = accuracy_score(y_test_other, y_pred)\n",
    "print(acc_test)\n",
    "acc_train=accuracy_score(y_train_other, model.predict(X_train_other_trans_scaled))\n",
    "print(acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={'test-accuracy': 0.9152542372881356, 'train-accuracy': 0.9296040226272785}, params={}, tags={'mlflow.runName': '5_SVM_other_scaled_trans',\n",
       " 'mlflow.source.git.commit': 'd605302d01200a4536da993e7ae45ed46232dc60',\n",
       " 'mlflow.source.name': '/Users/tamarapallien/neuefische/capstone '\n",
       "                       '/ds-capstone-alzheimers-/.venv/lib/python3.9/site-packages/ipykernel_launcher.py',\n",
       " 'mlflow.source.type': 'LOCAL',\n",
       " 'mlflow.user': 'tamarapallien'}>, info=<RunInfo: artifact_uri='s3://neuefische-mlflow/mlflow-artifacts/56/11b00a437afc4e5ea250ce17a0ecac02/artifacts', end_time=1661779946043, experiment_id='56', lifecycle_stage='active', run_id='11b00a437afc4e5ea250ce17a0ecac02', run_uuid='11b00a437afc4e5ea250ce17a0ecac02', start_time=1661779945723, status='FINISHED', user_id='tamarapallien'>>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"accuracy\", acc_train)\n",
    "mlflow.log_metric(\"test-\" + \"accuracy\", acc_test)\n",
    "\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()\n",
    "\n",
    "mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try the GridSearch on df_other \n",
    "#Try out as simple DNN model \n",
    "mlflow.start_run(run_name='6_SVM_gs_other_scaled_trans')\n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 420 candidates, totalling 2100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid=[{'C': [0.01, 0.1, 1, 10, 100], 'degree': [2, 3, 4],\n",
       "                          'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 'auto',\n",
       "                                    'scale'],\n",
       "                          'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}],\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the SVM performed the best we will perform a GridSearch to see if we can improve our outcome \n",
    "# Define hyperparameter grid \n",
    "param_grid = [{'kernel': ['rbf', 'linear', 'poly', 'sigmoid'], \n",
    "               'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 'auto', 'scale'],\n",
    "               'C': [0.01, 0.1, 1, 10, 100],\n",
    "               'degree': [2, 3, 4]\n",
    "              }]\n",
    "\n",
    "gs = GridSearchCV(SVC(), param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train_other_trans_scaled, y_train_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "best_model = gs.best_estimator_\n",
    "y_pred_tuned = best_model.predict(X_test_other_trans_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9246704331450094\n"
     ]
    }
   ],
   "source": [
    "# Check out the metrics\n",
    "acc_train = accuracy_score(y_train_other, best_model.predict(X_train_other_trans_scaled))\n",
    "acc_test = accuracy_score(y_test_other, y_pred_tuned)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={'test-accuracy': 0.9246704331450094, 'train-accuracy': 0.9327467001885607}, params={}, tags={'mlflow.runName': '6_SVM_gs_other_scaled_trans',\n",
       " 'mlflow.source.git.commit': 'd605302d01200a4536da993e7ae45ed46232dc60',\n",
       " 'mlflow.source.name': '/Users/tamarapallien/neuefische/capstone '\n",
       "                       '/ds-capstone-alzheimers-/.venv/lib/python3.9/site-packages/ipykernel_launcher.py',\n",
       " 'mlflow.source.type': 'LOCAL',\n",
       " 'mlflow.user': 'tamarapallien'}>, info=<RunInfo: artifact_uri='s3://neuefische-mlflow/mlflow-artifacts/56/4ea6893f19954f7d967d8284296c8a94/artifacts', end_time=1661779992644, experiment_id='56', lifecycle_stage='active', run_id='4ea6893f19954f7d967d8284296c8a94', run_uuid='4ea6893f19954f7d967d8284296c8a94', start_time=1661779946206, status='FINISHED', user_id='tamarapallien'>>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"accuracy\", acc_train)\n",
    "mlflow.log_metric(\"test-\" + \"accuracy\", acc_test)\n",
    "\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()\n",
    "\n",
    "mlflow.get_run(run_id=run.info.run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68df357d1236ea760662511d700563405db38e78ff847247caa8274b511a18ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
